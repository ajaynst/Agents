{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f5b7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install \\\n",
    "#   groq requests \\\n",
    "#   langgraph langchain langchain-community langchain-groq \\\n",
    "#   llama-index llama-index-llms-groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6a093ff2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c7ba85cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello! It's nice to meet you. Is there something I can help you with or would you like to chat?\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 24, 'prompt_tokens': 11, 'total_tokens': 35, 'completion_time': 0.055389591, 'completion_tokens_details': None, 'prompt_time': 4.7969e-05, 'prompt_tokens_details': None, 'queue_time': 0.049360271, 'total_time': 0.05543756}, 'model_name': 'meta-llama/llama-4-scout-17b-16e-instruct', 'system_fingerprint': 'fp_37da608fc1', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b7291-7dc0-75d0-b8bf-0e29fe68e2a5-0', usage_metadata={'input_tokens': 11, 'output_tokens': 24, 'total_tokens': 35})"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "llm.invoke(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "dddcb974",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "def local_math(expression: str) -> str:\n",
    "    \"\"\"for calculating any mathematical expressions\n",
    "        args: math expression as string\n",
    "        return: string\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # builtins rm access to open, exec, __import__, print\n",
    "        # this restricts - eval(\"__import__('os').system('rm -rf /')\")\n",
    "        return str(eval(expression, {\"__builtins__\": {}}))\n",
    "    except Exception as e:\n",
    "        return f\"Math error: {e}\"\n",
    "\n",
    "def guess_gender(name: str) -> str:\n",
    "    \"\"\"API to guess gender from a name\n",
    "        arg: name as string\n",
    "        return: string\n",
    "    \"\"\"\n",
    "    r = requests.get(\"https://api.genderize.io\", params={\"name\": name}, timeout=5)\n",
    "    return str(r.json()['gender']) # json object - {\"count\":6440, \"name\":\"ajay\", \"gender\":\"male\", \"probability\":0.99}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "84e331f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'21'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_math(\"3*7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "27f4f7fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'male'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "guess_gender(\"ajay\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9698f627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Guess the gender of velu\n",
      "None\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  guess_gender (hjmxp24zg)\n",
      " Call ID: hjmxp24zg\n",
      "  Args:\n",
      "    name: velu\n",
      "None\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: guess_gender\n",
      "\n",
      "male\n",
      "None\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The gender of Velu is male.\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import create_agent\n",
    "\n",
    "\n",
    "tools = [local_math, guess_gender]\n",
    "\n",
    "prompt = (\n",
    "    \"You have access to a tools that can do math and guess gender based on name given. \"\n",
    "    \"Use the tool to help answer user queries.\"\n",
    ")\n",
    "agent = create_agent(llm, tools, system_prompt=prompt)\n",
    "\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"What is 4*2+2\"},\n",
    "    {\"role\": \"user\", \"content\": \"Guess the gender of velu\"},\n",
    "]\n",
    "\n",
    "for event in agent.stream(\n",
    "    {\"messages\": messages},\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    print(event[\"messages\"][-1].pretty_print())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a124a733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': '12 * 9', 'result': '108'}\n",
      "{'query': 'Guess gender of rohitha', 'result': 'male'}\n",
      "{'query': 'Explain ai agents', 'result': 'No tool available for this query'}\n"
     ]
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph\n",
    "from typing import TypedDict, Optional\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    query: str\n",
    "    result: Optional[str]\n",
    "\n",
    "def router(state: AgentState):\n",
    "    q = state[\"query\"].lower()\n",
    "\n",
    "    if any(c.isdigit() for c in q):\n",
    "        return \"math\"\n",
    "\n",
    "    if \"gender\" in q or \"name\" in q:\n",
    "        return \"api\"\n",
    "\n",
    "    return \"no_tool\"\n",
    "\n",
    "\n",
    "def math_node(state: AgentState):\n",
    "    return {\"result\": local_math(state[\"query\"])}\n",
    "\n",
    "def api_node(state: AgentState):\n",
    "    name = state[\"query\"].split()[-1]\n",
    "    return {\"result\": guess_gender(name)}\n",
    "\n",
    "def no_tool_node(state: AgentState):\n",
    "    return {\"result\": \"No tool available for this query\"}\n",
    "\n",
    "\n",
    "graph = StateGraph(AgentState)\n",
    "\n",
    "graph.add_node(\"router\", lambda s: s)\n",
    "graph.add_node(\"math\", math_node)\n",
    "graph.add_node(\"api\", api_node)\n",
    "graph.add_node(\"no_tool\", no_tool_node)\n",
    "\n",
    "graph.set_entry_point(\"router\")\n",
    "\n",
    "graph.add_conditional_edges(\n",
    "    \"router\",\n",
    "    router,\n",
    "    {\n",
    "        \"math\": \"math\",\n",
    "        \"api\": \"api\",\n",
    "        \"no_tool\": \"no_tool\",\n",
    "    },\n",
    ")\n",
    "\n",
    "graph.set_finish_point(\"math\")\n",
    "graph.set_finish_point(\"api\")\n",
    "graph.set_finish_point(\"no_tool\")\n",
    "\n",
    "agent = graph.compile()\n",
    "\n",
    "\n",
    "m1 = agent.invoke({\"query\": \"12 * 9\"})\n",
    "m2 = agent.invoke({\"query\": \"Guess gender of rohitha\"})\n",
    "m3 = agent.invoke({\"query\": \"Explain ai agents\"})\n",
    "\n",
    "print(m1)\n",
    "print(m2)\n",
    "print(m3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "baa36daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "config:\n",
      "  flowchart:\n",
      "    curve: linear\n",
      "---\n",
      "graph TD;\n",
      "\t__start__([<p>__start__</p>]):::first\n",
      "\trouter(router)\n",
      "\tmath(math)\n",
      "\tapi(api)\n",
      "\tno_tool(no_tool)\n",
      "\t__end__([<p>__end__</p>]):::last\n",
      "\t__start__ --> router;\n",
      "\trouter -.-> api;\n",
      "\trouter -.-> math;\n",
      "\trouter -.-> no_tool;\n",
      "\tapi --> __end__;\n",
      "\tmath --> __end__;\n",
      "\tno_tool --> __end__;\n",
      "\tclassDef default fill:#f2f0ff,line-height:1.2\n",
      "\tclassDef first fill-opacity:0\n",
      "\tclassDef last fill:#bfb6fc\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mermaid = agent.get_graph().draw_mermaid()\n",
    "print(mermaid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "90bae22b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n",
      "[ToolCallResult(tool_name='local_math', tool_kwargs={'expression': '20+(2*4)'}, tool_id='7f360737-4a44-4940-97f6-71cf2cf29215', tool_output=ToolOutput(blocks=[TextBlock(block_type='text', text='28')], tool_name='local_math', raw_input={'args': (), 'kwargs': {'expression': '20+(2*4)'}}, raw_output='28', is_error=False), return_direct=False)]\n",
      "male\n",
      "[ToolCallResult(tool_name='guess_gender', tool_kwargs={'name': 'rahul'}, tool_id='c1042e11-01aa-4873-ba23-828b37d8fb06', tool_output=ToolOutput(blocks=[TextBlock(block_type='text', text='male')], tool_name='guess_gender', raw_input={'args': (), 'kwargs': {'name': 'rahul'}}, raw_output='male', is_error=False), return_direct=False)]\n"
     ]
    }
   ],
   "source": [
    "from llama_index.llms.groq import Groq\n",
    "from llama_index.core.agent.workflow import ReActAgent\n",
    "from llama_index.core.workflow import Context\n",
    "\n",
    "llm = Groq(model=\"meta-llama/llama-4-scout-17b-16e-instruct\", temperature=0)\n",
    "agent = ReActAgent(tools=[local_math, guess_gender], llm=llm, streaming=False)\n",
    "\n",
    "# context to store the convo history/session state\n",
    "ctx = Context(agent)\n",
    "\n",
    "# 1st qn\n",
    "handler1 = agent.run(\"What is 20+(2*4)?\", ctx=ctx)\n",
    "response1 = await handler1\n",
    "\n",
    "print(response1)\n",
    "print(response1.tool_calls)\n",
    "\n",
    "# 2nd qn (same ctx)\n",
    "handler2 = agent.run(\"What is the gender of rahul?\", ctx=ctx)\n",
    "response2 = await handler2\n",
    "\n",
    "print(response2)\n",
    "print(response2.tool_calls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d3b2fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
